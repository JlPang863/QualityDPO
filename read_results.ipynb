{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results DataFrame (Reordered with Average, Percentage Format):\n",
      "\n",
      "                                              mmlu  truthfulqa_mc2  hellaswag  arc_challenge  gsm8k  winogrande  Average\n",
      "sft                                          59.77           42.86      61.91          54.95   38.5       76.89     55.8\n",
      "dpo                                          57.57           53.14      64.34          57.19   30.5       78.33     56.8\n",
      "cpo                                          58.12           46.93      60.33          52.28   35.5       77.29     55.1\n",
      "kto                                          59.73           56.51      65.18          59.43   39.0       78.09     59.7\n",
      "simpo                                        58.49           50.68      63.89          59.26   35.5       78.41     57.7\n",
      "dpo-sorted-mistral-full                      59.08           45.97      65.12          60.38   28.5       77.37     56.1\n",
      "ours4-6-sorted-score-diff-new-base-full-lr5  59.73           52.07      65.78          60.21   38.5       77.77     59.0\n",
      "\n",
      "################################################################################\n",
      "LaTeX Form:\n",
      "################################################################################\n",
      "\\begin{table}\n",
      "\\caption{模型评估结果}\n",
      "\\label{tab:results}\n",
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      " & mmlu & truthfulqa_mc2 & hellaswag & arc_challenge & gsm8k & winogrande & Average \\\\\n",
      "\\midrule\n",
      "sft & 59.77 & 42.86 & 61.91 & 54.95 & 38.50 & 76.89 & 55.80 \\\\\n",
      "dpo & 57.57 & 53.14 & 64.34 & 57.19 & 30.50 & 78.33 & 56.80 \\\\\n",
      "cpo & 58.12 & 46.93 & 60.33 & 52.28 & 35.50 & 77.29 & 55.10 \\\\\n",
      "kto & 59.73 & 56.51 & 65.18 & 59.43 & 39.00 & 78.09 & 59.70 \\\\\n",
      "simpo & 58.49 & 50.68 & 63.89 & 59.26 & 35.50 & 78.41 & 57.70 \\\\\n",
      "dpo-sorted-mistral-full & 59.08 & 45.97 & 65.12 & 60.38 & 28.50 & 77.37 & 56.10 \\\\\n",
      "ours4-6-sorted-score-diff-new-base-full-lr5 & 59.73 & 52.07 & 65.78 & 60.21 & 38.50 & 77.77 & 59.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def model_file_path(base_model: str, loss_type: str, model_output_path: str):\n",
    "    # Base model name mapping\n",
    "    base_model_name_map = {\n",
    "        \"llama-3-8b\": \"Llama-3-Base-8B-SFT\",\n",
    "        \"mistral-7b\": \"Mistral-7B-Base-SFT\",\n",
    "        \"qwen-2.5-7b\": \"Qwen2.5-7B-sft-ultrachat\"\n",
    "    }\n",
    "    \n",
    "    base_model_name = base_model_name_map.get(base_model, base_model)\n",
    "\n",
    "    # Construct model output path\n",
    "    if loss_type == \"sft\":\n",
    "        if base_model == \"llama-3-8b\":\n",
    "            model_output_file = os.path.join(model_output_path, \"Llama-3-Base-8B-SFT\")\n",
    "        elif base_model == \"mistral-7b\":\n",
    "            model_output_file = os.path.join(model_output_path, \"mistral-7b-sft-beta\")\n",
    "        elif base_model == \"qwen-2.5-7b\":\n",
    "            model_output_file = os.path.join(model_output_path, \"Qwen2.5-7B-sft-ultrachat\")\n",
    "        else:\n",
    "            model_output_file = os.path.join(model_output_path, f\"{base_model}-sft\")\n",
    "    elif loss_type.lower() in [\"ipo\", \"kto\", \"cpo\", \"rdpo\", \"orpo\", \"slic-hf\", \"dpo\"]:\n",
    "        model_output_file = os.path.join(model_output_path, f\"{base_model_name}-{loss_type.upper()}\")\n",
    "    elif loss_type.lower() in [\"simpo\"]:\n",
    "        model_output_file = os.path.join(model_output_path, f\"{base_model_name}-SimPO\")\n",
    "    else:\n",
    "        model_output_file = os.path.join(model_output_path, f\"{base_model}-{loss_type}\")\n",
    "\n",
    "    return base_model_name, model_output_file\n",
    "\n",
    "\n",
    "#####################################\n",
    "# base_model = \"llama-3-8b\"\n",
    "# base_model = \"mistral-7b\"\n",
    "\n",
    "\n",
    "if base_model == \"llama-3-8b\":\n",
    "    loss_type_list = [\n",
    "        \"sft\", \"dpo\", \"cpo\", \"kto\", \"simpo\",\n",
    "        \"dpo-sorted-llama-full-ckpt-191\",\n",
    "        \"ours4-6-sorted-score-diff-full\"\n",
    "    ]\n",
    "elif base_model == \"mistral-7b\":\n",
    "    loss_type_list = [\n",
    "        \"sft\", \"dpo\", \"cpo\", \"kto\", \"simpo\",\n",
    "        \"dpo-sorted-mistral-full\",\n",
    "        \"ours4-6-sorted-score-diff-new-base-full-lr5\"\n",
    "    ]\n",
    "\n",
    "# Task list\n",
    "TASK_LISTS = [\n",
    "    'mmlu', 'bbh', 'gsm8k', 'truthfulqa_mc2', 'arc_challenge', 'piqa',\n",
    "    'hellaswag', 'openbookqa', 'triviaqa', 'sciq', 'arc_easy', 'logiqa',\n",
    "    'boolq', 'winogrande'\n",
    "]\n",
    "\n",
    "# Aggregate results\n",
    "results_all = {}\n",
    "for loss_type in loss_type_list:\n",
    "    data_root = \"./downstream_task_results\"\n",
    "    base_model_name, model_path = model_file_path(base_model, loss_type, data_root)\n",
    "\n",
    "    try:\n",
    "        # Expecting one subfolder inside each model directory\n",
    "        subfolder = os.listdir(model_path)[0]\n",
    "        data_path = os.path.join(model_path, subfolder)\n",
    "        json_files = [f for f in os.listdir(data_path) if f.endswith(\".json\")]\n",
    "    except Exception as e:\n",
    "        print(f\"[Warning] Failed to locate result path for {loss_type}: {e}\")\n",
    "        continue\n",
    "\n",
    "    results = {}\n",
    "    for file in json_files:\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        with open(file_path, 'r') as f:\n",
    "            temp = json.load(f)\n",
    "\n",
    "        for task in TASK_LISTS:\n",
    "            if task in temp.get('results', {}):\n",
    "                if task in ['hellaswag', 'piqa', 'openbookqa', 'arc_challenge', 'mmlu', 'truthfulqa_mc2', 'sciq', 'arc_easy', 'logiqa', 'boolq', 'winogrande']:\n",
    "                    metric = 'acc,none'\n",
    "                elif task == 'gsm8k':\n",
    "                    metric = 'exact_match,strict-match'\n",
    "                elif task == 'triviaqa':\n",
    "                    metric = 'exact_match,remove_whitespace'\n",
    "                elif task == 'bbh':\n",
    "                    metric = 'exact_match,get-answer'\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                value = temp['results'][task].get(metric)\n",
    "                if value is not None:\n",
    "                    results[task] = value\n",
    "\n",
    "    results_all[loss_type] = results\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame.from_dict(results_all, orient='index')\n",
    "\n",
    "# Select major task list and convert to percentage\n",
    "display_tasks = ['mmlu', \"truthfulqa_mc2\", \"hellaswag\", \"arc_challenge\", \"gsm8k\", 'winogrande']\n",
    "results_df = results_df[display_tasks]\n",
    "results_df = results_df.map(lambda x: round(100 * x, 2) if pd.notnull(x) else x)\n",
    "results_df['Average'] = results_df.mean(axis=1).round(1)\n",
    "\n",
    "# Order and print\n",
    "results_df = results_df.reindex(loss_type_list)\n",
    "results_df.index = results_df.index.str.replace('_', '-', regex=False)\n",
    "\n",
    "print(\"\\nResults DataFrame (Reordered with Average, Percentage Format):\\n\")\n",
    "print(results_df.to_string(line_width=1000))\n",
    "\n",
    "# Export LaTeX\n",
    "latex_table = results_df.to_latex(index=True, caption=\"模型评估结果\", label=\"tab:results\", float_format=\"%.2f\")\n",
    "print(\"\\n\" + \"#\" * 80 + \"\\nLaTeX Form:\\n\" + \"#\" * 80)\n",
    "print(latex_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
