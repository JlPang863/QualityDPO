# Quality Preference Optimization (QualPO)


This repository is to analyze the sample-level data quality impact under the DPO setting. The code base is from [SimPO](https://github.com/princeton-nlp/SimPO). Corresponding hyper-parameters follows the same setting used in SimPO repo. Please check SimPO's `README` file.


# Quick Start

One can run the code by 
```
bash run_all.sh
```